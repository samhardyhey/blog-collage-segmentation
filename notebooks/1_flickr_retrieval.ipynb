{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.getflickr_retrieval_logger().setLevel(logging.INFO)\n",
    "flickr_retrieval_logger = logging.getLogger(\"flickr_retrieval\")\n",
    "flickr_retrieval_logger.setLevel(logging.INFO)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_url_etree(image_id):\n",
    "    sizes = flickr.photos.getSizes(photo_id=image_id)\n",
    "    largest_available_size = (\n",
    "        pd.DataFrame([dict(e.items()) for e in list(sizes.find(\"sizes\"))])\n",
    "        .sort_values(by=[\"width\", \"height\"], ascending=True)\n",
    "        .iloc[0]\n",
    "    )\n",
    "    return largest_available_size.to_dict()\n",
    "\n",
    "\n",
    "def retrieve_image_meta_data(album_id, n_images_per_album=30, min_resolution=800):\n",
    "    image_records = []\n",
    "    try:\n",
    "        images_raw = list(flickr.walk_set(album_id))\n",
    "    except:\n",
    "        flickr_retrieval_logger.error(f\"Unable to walk images for album: {album_id}\")\n",
    "        return pd.DataFrame()  # cat empty df all the same? bit yikes\n",
    "\n",
    "    for image in tqdm(\n",
    "        images_raw, desc=f\"Retrieving image meta data for album: {album_id}\"\n",
    "    ):\n",
    "        image = dict(image.items())  # silly e-tree format\n",
    "        try:\n",
    "            largest_size = get_image_url_etree(image[\"id\"])\n",
    "            image[\"image_meta\"] = largest_size\n",
    "            image_records.append(image)\n",
    "        except:\n",
    "            flickr_retrieval_logger.error(\n",
    "                f\"Unable to retrieve image size for: {image['id']}\"\n",
    "            )\n",
    "\n",
    "    images = (\n",
    "        pd.DataFrame(image_records)\n",
    "        .assign(album_id=album_id)\n",
    "        .assign(download_url=lambda x: x.image_meta.apply(lambda y: y[\"source\"]))\n",
    "        # filter out small images\n",
    "        .assign(width=lambda x: x.image_meta.apply(lambda y: int(y[\"width\"])))\n",
    "        .assign(height=lambda x: x.image_meta.apply(lambda y: int(y[\"height\"])))\n",
    "        .query(\"height >= @min_resolution & width >= @min_resolution\")\n",
    "        .pipe(\n",
    "            lambda x: x.sample(n=n_images_per_album, random_state=42)\n",
    "            if x.shape[0] > n_images_per_album\n",
    "            else x\n",
    "        )\n",
    "    )\n",
    "    if len(images) == 0:\n",
    "        flickr_retrieval_logger.warning(\n",
    "            f\"No images meet the minimum resolution of {min_resolution}; {len(image_records)} initial records found\"\n",
    "        )\n",
    "    return images\n",
    "\n",
    "\n",
    "def download_flickr_image(url, save_path):\n",
    "    response = requests.get(url)\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "def download_image_record(record, download_dir):\n",
    "    # mkdir album save dir if doesn't exist\n",
    "    if (download_dir / record.album_id).exists() == False:\n",
    "        (download_dir / record.album_id).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_path = f\"{(download_dir / record.album_id / record.id).as_posix()}{Path(record.download_url).suffix}\"\n",
    "    print(save_path)\n",
    "    if Path(save_path).exists() == True:\n",
    "        flickr_retrieval_logger.info(f\"Previously saved: {save_path}; skipping\")\n",
    "    else:\n",
    "        try:\n",
    "            download_flickr_image(record.download_url, save_path)\n",
    "        except Exception:\n",
    "            flickr_retrieval_logger.error(\n",
    "                f\"Unable to download image at: {record.download_url}\"\n",
    "            )\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_api_key = os.getenv(\"FLICKR_API_KEY\")\n",
    "flickr_api_secret = os.environ.get(\"FLICKR_API_SECRET\")\n",
    "\n",
    "flickr = flickrapi.FlickrAPI(\n",
    "    flickr_api_key, flickr_api_secret, format=\"etree\"\n",
    ")  # json format also available\n",
    "flickr.authenticate_console()  # 401 error anyway? but still works?\n",
    "# flickr.authenticate_via_browser(perms='write')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_albums = 1\n",
    "n_images_per_album = 10\n",
    "user_id = \"61021753@N02\"\n",
    "\n",
    "# retrieve some biodiversity albums\n",
    "bdhl = flickr.imagesets.getList(user_id=user_id, page=1)  # paginated\n",
    "bdhl_df = pd.DataFrame([dict(e.items()) for e in list(bdhl.find(\"imagesets\"))]).sample(\n",
    "    n=n_albums, random_state=42\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_albums = [\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719480387299\",\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719533382815\",\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719491069662\",\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719531520295\",\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719464598717\",\n",
    "    \"https://www.flickr.com/photos/biodivlibrary/albums/72157719464733002\",\n",
    "]\n",
    "curated_albums = [Path(e).name for e in curated_albums]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk the albums, retrieve individual image details\n",
    "all_images = [retrieve_image_meta_data(album) for album in curated_albums]\n",
    "all_images = pd.concat(all_images)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# download each image\n",
    "download_dir = Path(\"../output/bdhl_flickr_downloads\")\n",
    "shutil.rmtree(str(download_dir)) if download_dir.exists() else None\n",
    "download_dir.mkdir()\n",
    "\n",
    "bio_diversity_all = all_images.progress_apply(\n",
    "    lambda y: download_image_record(y, download_dir), axis=1\n",
    ")\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blog.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b352da5c727154a09156c935f17a9c4d49b2c9c0946f47ddfcca219f38b45087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
